{"cells":[{"cell_type":"markdown","source":["Tutorial: Training models in Azure Databricks and deploying them on Azure ML\n\nThis notebook demostrates how to train models in Azure Databricks (or any Databricks implementation) and deploying those models on Azure ML.\n\nTraining and tracking experiments in Azure Databricks with Model Registries in Azure ML: This example shows how to do training and tracking of models in Azure Databricks. Tracking of experiments happens here in the MLflow instance running on Azure Databricks. However, model registries are kept on Azure ML to allow quick model's deployment from a centralized location and registry of models."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b1bf8f2-8b19-44ce-8e34-ff859162100d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Mount the training data from azure blob store to dbfs : /dbfs/mnt/training-data/diabetes-training"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dcba9cc2-fa6a-4250-bdd2-12e02b10368d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",                      \n       \"fs.azure.account.oauth2.client.id\": \"<client-id>\",\n       \"fs.azure.account.oauth2.client.secret\": \"<client-secert>\",\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/<tenate-id>/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n\ndbutils.fs.mount(\nsource = \"abfss://container@storage.dfs.core.windows.net/\",\nmount_point = \"/mnt/training-data\",\nextra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1f3f6b89-dee8-4977-b93c-6454d8764ace","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-416402486082469&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>        &#34;fs.azure.createRemoteFileSystemDuringInitialization&#34;: &#34;true&#34;}\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\"> dbutils.fs.mount(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      9</span> source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;abfss://databricks-data@vmaluml5712272503.dfs.core.windows.net/&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> mount_point <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/mnt/training-data&#34;</span><span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    387</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    388</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 389</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    390</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    391</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o375.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:756)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:776)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:461)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:826)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:607)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:815)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:469)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:114)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:347)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:306)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:120)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:147)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:147)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:102)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:543)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:659)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:400)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:398)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:395)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:443)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:428)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:552)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:543)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:513)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:101)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:947)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:947)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:863)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:499)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:475)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:316)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:400)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:398)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:395)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:443)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:428)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:50)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:316)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:157)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:475)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:372)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\tat java.lang.Thread.run(Thread.java:750)\n</div>","errorSummary":"java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data; nested exception is: ","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-416402486082469&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>        &#34;fs.azure.createRemoteFileSystemDuringInitialization&#34;: &#34;true&#34;}\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\"> dbutils.fs.mount(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      9</span> source <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;abfss://databricks-data@vmaluml5712272503.dfs.core.windows.net/&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> mount_point <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;/mnt/training-data&#34;</span><span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    387</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    388</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 389</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    390</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    391</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o375.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:756)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:776)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/training-data\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:461)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:826)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:607)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:815)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:469)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:114)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:347)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:306)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:120)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:147)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:147)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:102)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:543)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:659)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:400)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:398)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:395)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:443)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:428)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:552)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:543)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:513)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:101)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:947)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:947)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:863)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:499)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:475)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:316)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:400)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:398)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:395)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:50)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:443)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:428)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:50)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:316)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:157)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:475)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:372)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\tat java.lang.Thread.run(Thread.java:750)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Run next cell to install latest version of library"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"821ed15b-aabb-43f2-a6e5-941befa8a380","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install azureml-mlflow\n%pip install azure-ai-ml\n%pip install mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2cd9f74f-4d2e-4ea9-affc-abe72cab502d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting azureml-mlflow\n  Using cached azureml_mlflow-1.47.0-py3-none-any.whl (811 kB)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (2.8.1)\nCollecting azure-storage-blob&lt;=12.13.0,&gt;=12.5.0\n  Using cached azure_storage_blob-12.13.0-py3-none-any.whl (377 kB)\nCollecting azure-mgmt-core&lt;2.0.0,&gt;=1.2.0\n  Using cached azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting azure-common&lt;2.0.0,&gt;=1.1\n  Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting azure-identity\n  Using cached azure_identity-1.12.0-py3-none-any.whl (135 kB)\nRequirement already satisfied: mlflow-skinny in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (1.24.0)\nCollecting azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0\n  Using cached azure_core-1.26.1-py3-none-any.whl (172 kB)\nCollecting msrest&gt;=0.6.18\n  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting jsonpickle\n  Using cached jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nRequirement already satisfied: cryptography in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (3.4.7)\nRequirement already satisfied: requests&gt;=2.18.4 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (2.25.1)\nCollecting typing-extensions&gt;=4.0.1\n  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (1.15.0)\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography-&gt;azureml-mlflow) (1.14.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography-&gt;azureml-mlflow) (2.20)\nRequirement already satisfied: isodate&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (0.6.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (2020.12.5)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (1.3.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (2.10)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (4.0.0)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.18-&gt;azureml-mlflow) (3.1.0)\nCollecting msal&lt;2.0.0,&gt;=1.12.0\n  Using cached msal-1.20.0-py2.py3-none-any.whl (90 kB)\nCollecting msal-extensions&lt;2.0.0,&gt;=0.3.0\n  Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting PyJWT[crypto]&lt;3,&gt;=1.0.0\n  Using cached PyJWT-2.6.0-py3-none-any.whl (20 kB)\nCollecting portalocker&lt;3,&gt;=1.0\n  Using cached portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: click&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (7.1.2)\nRequirement already satisfied: databricks-cli&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (0.16.3)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (1.6.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (21.3)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (2020.5)\nRequirement already satisfied: gitpython&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.1.12)\nRequirement already satisfied: pyyaml&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (5.4.1)\nRequirement already satisfied: protobuf&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.17.2)\nRequirement already satisfied: importlib-metadata!=4.7.0,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.10.0)\nRequirement already satisfied: entrypoints in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (0.3)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow-skinny-&gt;azureml-mlflow) (0.8.7)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&gt;=2.1.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (4.0.7)\nRequirement already satisfied: smmap&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&gt;=2.1.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (3.0.5)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&gt;=3.7.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (3.4.1)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;mlflow-skinny-&gt;azureml-mlflow) (2.4.7)\nInstalling collected packages: PyJWT, typing-extensions, portalocker, msal, azure-core, msrest, msal-extensions, jsonpickle, azure-storage-blob, azure-mgmt-core, azure-identity, azure-common, azureml-mlflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;typing-extensions&#39;. No files were found to uninstall.\nSuccessfully installed PyJWT-2.6.0 azure-common-1.1.28 azure-core-1.26.1 azure-identity-1.12.0 azure-mgmt-core-1.3.2 azure-storage-blob-12.13.0 azureml-mlflow-1.47.0 jsonpickle-2.2.0 msal-1.20.0 msal-extensions-1.0.0 msrest-0.7.1 portalocker-2.6.0 typing-extensions-4.4.0\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting azure-ai-ml\n  Using cached azure_ai_ml-1.1.1-py3-none-any.whl (4.0 MB)\nCollecting azure-storage-file-datalake&lt;13.0.0\n  Using cached azure_storage_file_datalake-12.9.1-py3-none-any.whl (238 kB)\nRequirement already satisfied: pyjwt&lt;3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (2.6.0)\nRequirement already satisfied: isodate in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (0.6.0)\nCollecting opencensus-ext-azure&lt;2.0.0\n  Using cached opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\nRequirement already satisfied: pyyaml&lt;7.0.0,&gt;=5.1.0 in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (5.4.1)\nCollecting colorama&lt;0.5.0\n  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: azure-mgmt-core&lt;2.0.0,&gt;=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.3.2)\nCollecting pydash&lt;6.0.0\n  Using cached pydash-5.1.1-py3-none-any.whl (84 kB)\nCollecting strictyaml&lt;2.0.0\n  Using cached strictyaml-1.6.2-py3-none-any.whl\nRequirement already satisfied: tqdm&lt;5.0.0 in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (4.59.0)\nRequirement already satisfied: azure-common&lt;2.0.0,&gt;=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: typing-extensions&lt;5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (4.4.0)\nCollecting azure-storage-file-share&lt;13.0.0\n  Using cached azure_storage_file_share-12.10.1-py3-none-any.whl (252 kB)\nRequirement already satisfied: azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.26.1)\nRequirement already satisfied: msrest&gt;=0.6.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\nCollecting marshmallow&lt;4.0.0,&gt;=3.5\n  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\nCollecting jsonschema&lt;5.0.0,&gt;=4.0.0\n  Using cached jsonschema-4.17.1-py3-none-any.whl (90 kB)\nRequirement already satisfied: azure-storage-blob&lt;13.0.0,&gt;=12.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\nRequirement already satisfied: requests&gt;=2.18.4 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (2.25.1)\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (1.15.0)\nRequirement already satisfied: cryptography&gt;=2.1.4 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (3.4.7)\nCollecting azure-storage-blob&lt;13.0.0,&gt;=12.10.0\n  Using cached azure_storage_blob-12.14.1-py3-none-any.whl (383 kB)\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (1.14.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (2.20)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (0.17.3)\nCollecting pkgutil-resolve-name&gt;=1.3.10\n  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (20.3.0)\nCollecting importlib-resources&gt;=1.4.0\n  Using cached importlib_resources-5.10.0-py3-none-any.whl (34 kB)\nRequirement already satisfied: zipp&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (3.4.1)\nRequirement already satisfied: packaging&gt;=17.0 in /databricks/python3/lib/python3.8/site-packages (from marshmallow&lt;4.0.0,&gt;=3.5-&gt;azure-ai-ml) (21.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azure-ai-ml) (2020.12.5)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azure-ai-ml) (1.3.0)\nRequirement already satisfied: azure-identity&lt;2.0.0,&gt;=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.12.0)\nCollecting opencensus&lt;1.0.0,&gt;=0.11.0\n  Using cached opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\nRequirement already satisfied: psutil&gt;=5.6.3 in /databricks/python3/lib/python3.8/site-packages (from opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (5.8.0)\nRequirement already satisfied: msal&lt;2.0.0,&gt;=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.20.0)\nRequirement already satisfied: msal-extensions&lt;2.0.0,&gt;=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.0.0)\nRequirement already satisfied: portalocker&lt;3,&gt;=1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from msal-extensions&lt;2.0.0,&gt;=0.3.0-&gt;azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (2.6.0)\nCollecting opencensus-context&gt;=0.1.3\n  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-api-core&lt;3.0.0,&gt;=1.0.0\n  Using cached google_api_core-2.10.2-py3-none-any.whl (115 kB)\nCollecting googleapis-common-protos&lt;2.0dev,&gt;=1.56.2\n  Using cached googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\nCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.19.5\n  Using cached protobuf-4.21.9-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\nCollecting google-auth&lt;3.0dev,&gt;=1.25.0\n  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (4.7.2)\nRequirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (4.2.4)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (0.2.8)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=17.0-&gt;marshmallow&lt;4.0.0,&gt;=3.5-&gt;azure-ai-ml) (2.4.7)\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (0.4.8)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (2.10)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (4.0.0)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.18-&gt;azure-ai-ml) (3.1.0)\nRequirement already satisfied: python-dateutil&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from strictyaml&lt;2.0.0-&gt;azure-ai-ml) (2.8.1)\nInstalling collected packages: protobuf, googleapis-common-protos, google-auth, opencensus-context, google-api-core, pkgutil-resolve-name, opencensus, importlib-resources, azure-storage-blob, strictyaml, pydash, opencensus-ext-azure, marshmallow, jsonschema, colorama, azure-storage-file-share, azure-storage-file-datalake, azure-ai-ml\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.17.2\n    Not uninstalling protobuf at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;protobuf&#39;. No files were found to uninstall.\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 1.22.1\n    Not uninstalling google-auth at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;google-auth&#39;. No files were found to uninstall.\n  Attempting uninstall: azure-storage-blob\n    Found existing installation: azure-storage-blob 12.13.0\n    Uninstalling azure-storage-blob-12.13.0:\n      Successfully uninstalled azure-storage-blob-12.13.0\n  Attempting uninstall: jsonschema\n    Found existing installation: jsonschema 3.2.0\n    Not uninstalling jsonschema at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;jsonschema&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-mlflow 1.47.0 requires azure-storage-blob&lt;=12.13.0,&gt;=12.5.0, but you have azure-storage-blob 12.14.1 which is incompatible.\nSuccessfully installed azure-ai-ml-1.1.1 azure-storage-blob-12.14.1 azure-storage-file-datalake-12.9.1 azure-storage-file-share-12.10.1 colorama-0.4.6 google-api-core-2.10.2 google-auth-2.14.1 googleapis-common-protos-1.57.0 importlib-resources-5.10.0 jsonschema-4.17.1 marshmallow-3.19.0 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 pkgutil-resolve-name-1.3.10 protobuf-4.21.9 pydash-5.1.1 strictyaml-1.6.2\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting mlflow\n  Using cached mlflow-2.0.1-py3-none-any.whl (16.5 MB)\nRequirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.0)\nRequirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.16.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (7.1.2)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nRequirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.4.1)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pyarrow&lt;11,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (4.0.0)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nCollecting docker&lt;7,&gt;=4.0.0\n  Using cached docker-6.0.1-py3-none-any.whl (147 kB)\nRequirement already satisfied: scikit-learn&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.24.1)\nRequirement already satisfied: markdown&lt;4,&gt;=3.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.3.3)\nRequirement already satisfied: Jinja2&lt;4,&gt;=2.11 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.11.3)\nRequirement already satisfied: importlib-metadata!=4.7.0,&lt;6,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from mlflow) (4.21.9)\nRequirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (5.4.1)\nRequirement already satisfied: shap&lt;1,&gt;=0.40 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.40.0)\nCollecting alembic&lt;2\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\nRequirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.1.12)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nRequirement already satisfied: matplotlib&lt;4 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.4.2)\nCollecting sqlalchemy&lt;2,&gt;=1.4.0\n  Using cached SQLAlchemy-1.4.44-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nRequirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.0.4)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (21.3)\nRequirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.1.2)\nCollecting querystring-parser&lt;2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nRequirement already satisfied: importlib-resources in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (5.10.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (1.1.3)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (0.8.7)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;7,&gt;=4.0.0-&gt;mlflow) (0.57.0)\nCollecting urllib3&gt;=1.26.0\n  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\nCollecting requests&lt;3,&gt;=2.17.3\n  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\nRequirement already satisfied: itsdangerous&gt;=0.24 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (1.1.0)\nRequirement already satisfied: Werkzeug&gt;=0.15 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (1.0.1)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (4.0.7)\nRequirement already satisfied: smmap&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (3.0.5)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;6,&gt;=3.7.0-&gt;mlflow) (3.4.1)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&lt;4,&gt;=2.11-&gt;mlflow) (2.0.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (2.8.1)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (8.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (0.10.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (1.3.1)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nCollecting charset-normalizer&lt;3,&gt;=2\n  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow) (1.0.1)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow) (2.1.0)\nRequirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (0.55.1)\nRequirement already satisfied: tqdm&gt;4.25.0 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (4.59.0)\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (0.0.7)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (544 kB)\nRequirement already satisfied: llvmlite&lt;0.39,&gt;=0.38.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap&lt;1,&gt;=0.40-&gt;mlflow) (0.38.0)\nInstalling collected packages: urllib3, greenlet, charset-normalizer, sqlalchemy, requests, querystring-parser, docker, alembic, mlflow\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.25.11\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;urllib3&#39;. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;requests&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-mlflow 1.47.0 requires azure-storage-blob&lt;=12.13.0,&gt;=12.5.0, but you have azure-storage-blob 12.14.1 which is incompatible.\nbotocore 1.19.7 requires urllib3&lt;1.26,&gt;=1.25.4; python_version != &#34;3.4&#34;, but you have urllib3 1.26.13 which is incompatible.\nSuccessfully installed alembic-1.8.1 charset-normalizer-2.1.1 docker-6.0.1 greenlet-2.0.1 mlflow-2.0.1 querystring-parser-1.2.4 requests-2.28.1 sqlalchemy-1.4.44 urllib3-1.26.13\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting azureml-mlflow\n  Using cached azureml_mlflow-1.47.0-py3-none-any.whl (811 kB)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (2.8.1)\nCollecting azure-storage-blob&lt;=12.13.0,&gt;=12.5.0\n  Using cached azure_storage_blob-12.13.0-py3-none-any.whl (377 kB)\nCollecting azure-mgmt-core&lt;2.0.0,&gt;=1.2.0\n  Using cached azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting azure-common&lt;2.0.0,&gt;=1.1\n  Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting azure-identity\n  Using cached azure_identity-1.12.0-py3-none-any.whl (135 kB)\nRequirement already satisfied: mlflow-skinny in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (1.24.0)\nCollecting azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0\n  Using cached azure_core-1.26.1-py3-none-any.whl (172 kB)\nCollecting msrest&gt;=0.6.18\n  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting jsonpickle\n  Using cached jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nRequirement already satisfied: cryptography in /databricks/python3/lib/python3.8/site-packages (from azureml-mlflow) (3.4.7)\nRequirement already satisfied: requests&gt;=2.18.4 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (2.25.1)\nCollecting typing-extensions&gt;=4.0.1\n  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (1.15.0)\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography-&gt;azureml-mlflow) (1.14.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography-&gt;azureml-mlflow) (2.20)\nRequirement already satisfied: isodate&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (0.6.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (2020.12.5)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azureml-mlflow) (1.3.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (2.10)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azureml-mlflow) (4.0.0)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.18-&gt;azureml-mlflow) (3.1.0)\nCollecting msal&lt;2.0.0,&gt;=1.12.0\n  Using cached msal-1.20.0-py2.py3-none-any.whl (90 kB)\nCollecting msal-extensions&lt;2.0.0,&gt;=0.3.0\n  Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting PyJWT[crypto]&lt;3,&gt;=1.0.0\n  Using cached PyJWT-2.6.0-py3-none-any.whl (20 kB)\nCollecting portalocker&lt;3,&gt;=1.0\n  Using cached portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: click&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (7.1.2)\nRequirement already satisfied: databricks-cli&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (0.16.3)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (1.6.0)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (21.3)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (2020.5)\nRequirement already satisfied: gitpython&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.1.12)\nRequirement already satisfied: pyyaml&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (5.4.1)\nRequirement already satisfied: protobuf&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.17.2)\nRequirement already satisfied: importlib-metadata!=4.7.0,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (3.10.0)\nRequirement already satisfied: entrypoints in /databricks/python3/lib/python3.8/site-packages (from mlflow-skinny-&gt;azureml-mlflow) (0.3)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow-skinny-&gt;azureml-mlflow) (0.8.7)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&gt;=2.1.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (4.0.7)\nRequirement already satisfied: smmap&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&gt;=2.1.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (3.0.5)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&gt;=3.7.0-&gt;mlflow-skinny-&gt;azureml-mlflow) (3.4.1)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;mlflow-skinny-&gt;azureml-mlflow) (2.4.7)\nInstalling collected packages: PyJWT, typing-extensions, portalocker, msal, azure-core, msrest, msal-extensions, jsonpickle, azure-storage-blob, azure-mgmt-core, azure-identity, azure-common, azureml-mlflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;typing-extensions&#39;. No files were found to uninstall.\nSuccessfully installed PyJWT-2.6.0 azure-common-1.1.28 azure-core-1.26.1 azure-identity-1.12.0 azure-mgmt-core-1.3.2 azure-storage-blob-12.13.0 azureml-mlflow-1.47.0 jsonpickle-2.2.0 msal-1.20.0 msal-extensions-1.0.0 msrest-0.7.1 portalocker-2.6.0 typing-extensions-4.4.0\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting azure-ai-ml\n  Using cached azure_ai_ml-1.1.1-py3-none-any.whl (4.0 MB)\nCollecting azure-storage-file-datalake&lt;13.0.0\n  Using cached azure_storage_file_datalake-12.9.1-py3-none-any.whl (238 kB)\nRequirement already satisfied: pyjwt&lt;3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (2.6.0)\nRequirement already satisfied: isodate in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (0.6.0)\nCollecting opencensus-ext-azure&lt;2.0.0\n  Using cached opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\nRequirement already satisfied: pyyaml&lt;7.0.0,&gt;=5.1.0 in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (5.4.1)\nCollecting colorama&lt;0.5.0\n  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: azure-mgmt-core&lt;2.0.0,&gt;=1.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.3.2)\nCollecting pydash&lt;6.0.0\n  Using cached pydash-5.1.1-py3-none-any.whl (84 kB)\nCollecting strictyaml&lt;2.0.0\n  Using cached strictyaml-1.6.2-py3-none-any.whl\nRequirement already satisfied: tqdm&lt;5.0.0 in /databricks/python3/lib/python3.8/site-packages (from azure-ai-ml) (4.59.0)\nRequirement already satisfied: azure-common&lt;2.0.0,&gt;=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: typing-extensions&lt;5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (4.4.0)\nCollecting azure-storage-file-share&lt;13.0.0\n  Using cached azure_storage_file_share-12.10.1-py3-none-any.whl (252 kB)\nRequirement already satisfied: azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (1.26.1)\nRequirement already satisfied: msrest&gt;=0.6.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\nCollecting marshmallow&lt;4.0.0,&gt;=3.5\n  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\nCollecting jsonschema&lt;5.0.0,&gt;=4.0.0\n  Using cached jsonschema-4.17.1-py3-none-any.whl (90 kB)\nRequirement already satisfied: azure-storage-blob&lt;13.0.0,&gt;=12.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\nRequirement already satisfied: requests&gt;=2.18.4 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (2.25.1)\nRequirement already satisfied: six&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (1.15.0)\nRequirement already satisfied: cryptography&gt;=2.1.4 in /databricks/python3/lib/python3.8/site-packages (from azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (3.4.7)\nCollecting azure-storage-blob&lt;13.0.0,&gt;=12.10.0\n  Using cached azure_storage_blob-12.14.1-py3-none-any.whl (383 kB)\nRequirement already satisfied: cffi&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (1.14.5)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.1.4-&gt;azure-storage-blob&lt;13.0.0,&gt;=12.10.0-&gt;azure-ai-ml) (2.20)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (0.17.3)\nCollecting pkgutil-resolve-name&gt;=1.3.10\n  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: attrs&gt;=17.4.0 in /databricks/python3/lib/python3.8/site-packages (from jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (20.3.0)\nCollecting importlib-resources&gt;=1.4.0\n  Using cached importlib_resources-5.10.0-py3-none-any.whl (34 kB)\nRequirement already satisfied: zipp&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&lt;5.0.0,&gt;=4.0.0-&gt;azure-ai-ml) (3.4.1)\nRequirement already satisfied: packaging&gt;=17.0 in /databricks/python3/lib/python3.8/site-packages (from marshmallow&lt;4.0.0,&gt;=3.5-&gt;azure-ai-ml) (21.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azure-ai-ml) (2020.12.5)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /databricks/python3/lib/python3.8/site-packages (from msrest&gt;=0.6.18-&gt;azure-ai-ml) (1.3.0)\nRequirement already satisfied: azure-identity&lt;2.0.0,&gt;=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.12.0)\nCollecting opencensus&lt;1.0.0,&gt;=0.11.0\n  Using cached opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\nRequirement already satisfied: psutil&gt;=5.6.3 in /databricks/python3/lib/python3.8/site-packages (from opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (5.8.0)\nRequirement already satisfied: msal&lt;2.0.0,&gt;=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.20.0)\nRequirement already satisfied: msal-extensions&lt;2.0.0,&gt;=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (1.0.0)\nRequirement already satisfied: portalocker&lt;3,&gt;=1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from msal-extensions&lt;2.0.0,&gt;=0.3.0-&gt;azure-identity&lt;2.0.0,&gt;=1.5.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (2.6.0)\nCollecting opencensus-context&gt;=0.1.3\n  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-api-core&lt;3.0.0,&gt;=1.0.0\n  Using cached google_api_core-2.10.2-py3-none-any.whl (115 kB)\nCollecting googleapis-common-protos&lt;2.0dev,&gt;=1.56.2\n  Using cached googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\nCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.19.5\n  Using cached protobuf-4.21.9-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\nCollecting google-auth&lt;3.0dev,&gt;=1.25.0\n  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (4.7.2)\nRequirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (4.2.4)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (0.2.8)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=17.0-&gt;marshmallow&lt;4.0.0,&gt;=3.5-&gt;azure-ai-ml) (2.4.7)\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3.0dev,&gt;=1.25.0-&gt;google-api-core&lt;3.0.0,&gt;=1.0.0-&gt;opencensus&lt;1.0.0,&gt;=0.11.0-&gt;opencensus-ext-azure&lt;2.0.0-&gt;azure-ai-ml) (0.4.8)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (2.10)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.18.4-&gt;azure-core!=1.22.0,&lt;2.0.0,&gt;=1.8.0-&gt;azure-ai-ml) (4.0.0)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.6.18-&gt;azure-ai-ml) (3.1.0)\nRequirement already satisfied: python-dateutil&gt;=2.6.0 in /databricks/python3/lib/python3.8/site-packages (from strictyaml&lt;2.0.0-&gt;azure-ai-ml) (2.8.1)\nInstalling collected packages: protobuf, googleapis-common-protos, google-auth, opencensus-context, google-api-core, pkgutil-resolve-name, opencensus, importlib-resources, azure-storage-blob, strictyaml, pydash, opencensus-ext-azure, marshmallow, jsonschema, colorama, azure-storage-file-share, azure-storage-file-datalake, azure-ai-ml\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.17.2\n    Not uninstalling protobuf at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;protobuf&#39;. No files were found to uninstall.\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 1.22.1\n    Not uninstalling google-auth at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;google-auth&#39;. No files were found to uninstall.\n  Attempting uninstall: azure-storage-blob\n    Found existing installation: azure-storage-blob 12.13.0\n    Uninstalling azure-storage-blob-12.13.0:\n      Successfully uninstalled azure-storage-blob-12.13.0\n  Attempting uninstall: jsonschema\n    Found existing installation: jsonschema 3.2.0\n    Not uninstalling jsonschema at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;jsonschema&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-mlflow 1.47.0 requires azure-storage-blob&lt;=12.13.0,&gt;=12.5.0, but you have azure-storage-blob 12.14.1 which is incompatible.\nSuccessfully installed azure-ai-ml-1.1.1 azure-storage-blob-12.14.1 azure-storage-file-datalake-12.9.1 azure-storage-file-share-12.10.1 colorama-0.4.6 google-api-core-2.10.2 google-auth-2.14.1 googleapis-common-protos-1.57.0 importlib-resources-5.10.0 jsonschema-4.17.1 marshmallow-3.19.0 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 pkgutil-resolve-name-1.3.10 protobuf-4.21.9 pydash-5.1.1 strictyaml-1.6.2\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting mlflow\n  Using cached mlflow-2.0.1-py3-none-any.whl (16.5 MB)\nRequirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.0)\nRequirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.16.3)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (7.1.2)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nRequirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.4.1)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pyarrow&lt;11,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (4.0.0)\nRequirement already satisfied: pandas&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nCollecting docker&lt;7,&gt;=4.0.0\n  Using cached docker-6.0.1-py3-none-any.whl (147 kB)\nRequirement already satisfied: scikit-learn&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.24.1)\nRequirement already satisfied: markdown&lt;4,&gt;=3.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.3.3)\nRequirement already satisfied: Jinja2&lt;4,&gt;=2.11 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.11.3)\nRequirement already satisfied: importlib-metadata!=4.7.0,&lt;6,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from mlflow) (4.21.9)\nRequirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (5.4.1)\nRequirement already satisfied: shap&lt;1,&gt;=0.40 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.40.0)\nCollecting alembic&lt;2\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\nRequirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.1.12)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nRequirement already satisfied: matplotlib&lt;4 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.4.2)\nCollecting sqlalchemy&lt;2,&gt;=1.4.0\n  Using cached SQLAlchemy-1.4.44-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nRequirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.0.4)\nRequirement already satisfied: packaging&lt;22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (21.3)\nRequirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.1.2)\nCollecting querystring-parser&lt;2\n  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nRequirement already satisfied: importlib-resources in /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (5.10.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow) (1.1.3)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (0.8.7)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow) (1.15.0)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;7,&gt;=4.0.0-&gt;mlflow) (0.57.0)\nCollecting urllib3&gt;=1.26.0\n  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\nCollecting requests&lt;3,&gt;=2.17.3\n  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\nRequirement already satisfied: itsdangerous&gt;=0.24 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (1.1.0)\nRequirement already satisfied: Werkzeug&gt;=0.15 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow) (1.0.1)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (4.0.7)\nRequirement already satisfied: smmap&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow) (3.0.5)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow) (52.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;6,&gt;=3.7.0-&gt;mlflow) (3.4.1)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&lt;4,&gt;=2.11-&gt;mlflow) (2.0.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (2.8.1)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (8.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (0.10.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (1.3.1)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nCollecting charset-normalizer&lt;3,&gt;=2\n  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow) (1.0.1)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow) (2.1.0)\nRequirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (0.55.1)\nRequirement already satisfied: tqdm&gt;4.25.0 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (4.59.0)\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow) (0.0.7)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (544 kB)\nRequirement already satisfied: llvmlite&lt;0.39,&gt;=0.38.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap&lt;1,&gt;=0.40-&gt;mlflow) (0.38.0)\nInstalling collected packages: urllib3, greenlet, charset-normalizer, sqlalchemy, requests, querystring-parser, docker, alembic, mlflow\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.25.11\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;urllib3&#39;. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-53f1ab64-0884-422f-b62b-acefedd0fde9\n    Can&#39;t uninstall &#39;requests&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-mlflow 1.47.0 requires azure-storage-blob&lt;=12.13.0,&gt;=12.5.0, but you have azure-storage-blob 12.14.1 which is incompatible.\nbotocore 1.19.7 requires urllib3&lt;1.26,&gt;=1.25.4; python_version != &#34;3.4&#34;, but you have urllib3 1.26.13 which is incompatible.\nSuccessfully installed alembic-1.8.1 charset-normalizer-2.1.1 docker-6.0.1 greenlet-2.0.1 mlflow-2.0.1 querystring-parser-1.2.4 requests-2.28.1 sqlalchemy-1.4.44 urllib3-1.26.13\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Configure the following variables"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d69d2f4c-e727-4924-b0ac-37007c3008a7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["aml_region = \"\"\nsubscription_id = \"\"\naml_resource_group = \"\"\naml_workspace_name = \"\"\nadb_user_id = \"\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"61550992-1f2f-4546-b59e-43814fa0509d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["azureml_mlflow_uri=f\"azureml://{aml_region}.api.azureml.ms/mlflow/v1.0/subscriptions/{subscription_id}/resourceGroups/{aml_resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{aml_workspace_name}\"\nprint(azureml_mlflow_uri)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"616508b6-51a7-46a8-a736-073d1fa62298","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a63019f4-2005-489a-92e3-5fce495bcdfb/resourceGroups/dataintelligencerg-eastUS/providers/Microsoft.MachineLearningServices/workspaces/Databricks_AML\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a63019f4-2005-489a-92e3-5fce495bcdfb/resourceGroups/dataintelligencerg-eastUS/providers/Microsoft.MachineLearningServices/workspaces/Databricks_AML\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["In some cases we may want to keep doing tracking of experiments in the MLflow instance that comes with Azure Databricks. This is the case for instance of customers that were already using MLflow in Azure Databricks so they want to keep they existing experiments there. However, they may want to take adavantage of the deployment capabilities of Azure ML including managed inference solutions, no-code deployments, etc."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e1ac58cf-b11a-4aa8-af93-0a1445e82fad","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import warnings\n\nwarnings.simplefilter(\"ignore\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ca16cfb4-a29d-4b8c-ab0d-141254672684","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Configuring models' registry\n\nMLflow allows us to segregate the instance where experiments are being tracked from the instance where models' are being tracked (or registered). The first tutorial is referred to Tracking URI while the second one is referred as Registry URI. By default, both of them are set to the same value, and in Azure Databricks, both of them are set to \"databricks\" meaning that tracking and model registries will happen inside of the MLflow instance that Databricks runs for us.\n\nWe are going to track the experiments in Azure Databricks, but model registries will be held in Azure ML. This will allow us to manage the model's lifecycle - including deployments - in Azure ML."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f412a000-74ec-4b5a-ac4e-df8d4c69e156","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import mlflow\nmlflow.set_registry_uri(azureml_mlflow_uri)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7d64fe4-0026-48a4-ac8f-0eced1b94956","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Configuring the experiment\n\nTracking of experiments will happen in Azure Datbricks and hence we need to use the naming we use here."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ebf17052-5d83-42b3-b704-4325eba1cca0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["mlflow.set_experiment(experiment_name=f\"/Users/{adb_user_id}/diabetes-prediction-databricks\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a445c416-217a-479a-88d0-f348a2f7b7e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\n2022/11/28 09:30:30 INFO mlflow.tracking.fluent: Experiment with name &#39;/Users/vinitamalu@microsoft.com/diabetes-prediction-databricks&#39; does not exist. Creating a new experiment.\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nOut[9]: &lt;Experiment: artifact_location=&#39;&#39;, creation_time=1669627830552, experiment_id=&#39;caf30461-4746-480b-8482-e466e6865a0d&#39;, last_update_time=None, lifecycle_stage=&#39;active&#39;, name=&#39;/Users/vinitamalu@microsoft.com/diabetes-prediction-databricks&#39;, tags={}&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\n2022/11/28 09:30:30 INFO mlflow.tracking.fluent: Experiment with name &#39;/Users/vinitamalu@microsoft.com/diabetes-prediction-databricks&#39; does not exist. Creating a new experiment.\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nOut[9]: &lt;Experiment: artifact_location=&#39;&#39;, creation_time=1669627830552, experiment_id=&#39;caf30461-4746-480b-8482-e466e6865a0d&#39;, last_update_time=None, lifecycle_stage=&#39;active&#39;, name=&#39;/Users/vinitamalu@microsoft.com/diabetes-prediction-databricks&#39;, tags={}&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Exploring the data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a843c8de-ad14-4455-b748-a7f49930a033","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\ndf_diabetes = pd.read_csv('/dbfs/mnt/training/*.csv')\ndf_diabetes.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f76b6e5-7814-4b0c-bf2a-3be42be7963b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Training a diabetes prediction regression model"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1129d8fc-cd5f-4cdb-853f-c3e08b3c72c0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n# Separate features and labels\nX, y = df_diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df_diabetes['Diabetic'].values\n\n# Split data into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ec9a8073-33ac-4aba-a46e-2d451c5c5876","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We are going to use autologging capabilities in MLflow to track parameters and metrics."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8da0d7cd-b1c5-4053-8b17-52d1966d1c2d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["mlflow.autolog() #enable logging for sklearn models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"436252db-a38a-461d-8a53-6554bbf51ce4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2022/11/28 09:31:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2022/11/28 09:31:15 INFO mlflow._spark_autologging: Autologging successfully enabled for spark.\n2022/11/28 09:31:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n2022/11/28 09:31:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2022/11/28 09:31:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2022/11/28 09:31:15 INFO mlflow._spark_autologging: Autologging successfully enabled for spark.\n2022/11/28 09:31:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n2022/11/28 09:31:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Create a model & train it"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d6c04fc-2469-44b9-81fa-5e0d12d4eb98","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\n# Set regularization hyperparameter\nreg = 0.01\n\nwith mlflow.start_run() as run:\n    model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n    # calculate accuracy\n    y_hat = model.predict(X_test)\n    acc = np.average(y_hat == y_test)\n    # calculate AUC\n    y_scores = model.predict_proba(X_test)\n    auc = roc_auc_score(y_test,y_scores[:,1])\n    print(\"Accuracy: %.2f%%\" % (acc * 100.0))\n    print(\"AUC: %.2f%%\" % (auc * 100.0))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fd1f1f06-7795-4e44-bc11-338c5a64ec1e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nAccuracy: 77.40%\nAUC: 84.84%\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nAccuracy: 77.40%\nAUC: 84.84%\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Registering the model in Azure ML\n\nSo far, our model is trained and tracked inside of the MLflow instance in Azure Databricks. Now we want to register this model in Azure ML to manage the life cicle there. However, if we try to register the model as we usually do using the sintax mlflow.register_model(model_uri=f\"runs:/{run.info.run_id}/model\"). you will found an error. The reason why this is happening is related to where runs are being stored.\n\nRight now runs are being stored in Azure Databricks and models in Azure ML. If you try to create a registered model from a Run, Azure ML don't have any way to guess how to get access to the runs, that are stored in a different service. because of that, you can't use runs:/ URI for registering models.\n\nTo overcome this limitation, we have to register the model from the artifacts themselfs, which we can achieve by first downloading them."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"df5e2c22-ccda-4b4b-a60e-d070a3233d5a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["client = mlflow.tracking.MlflowClient()\nmodel_path = client.download_artifacts(run.info.run_id, path=\"model\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e61c3cd-d1e1-4ad4-b4cc-a355868d9c66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["model_path is a local path to the artifacts representing the MLmodel created. We can use this artifacts to register the model now:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"60cb165d-984c-44d5-b468-2ddd2274b84f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["mlflow.register_model(\n    model_uri=f\"file://{model_path}\", name=\"databricks-diabetes-prediction\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c692a719-e7e2-4837-a39a-d0c2fe2a4b24","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\nRegistered model &#39;databricks-diabetes-prediction&#39; already exists. Creating a new version of this model...\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\n2022/11/28 09:37:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: databricks-diabetes-prediction, version 1\nCreated version &#39;1&#39; of model &#39;databricks-diabetes-prediction&#39;.\nOut[16]: &lt;ModelVersion: creation_timestamp=1669628232008, current_stage=&#39;None&#39;, description=&#39;&#39;, last_updated_timestamp=1669628232008, name=&#39;databricks-diabetes-prediction&#39;, run_id=&#39;&#39;, run_link=&#39;&#39;, source=&#39;azureml://artifacts/LocalUpload/221128T093710-01597558/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;&#39;, version=&#39;1&#39;&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">InteractiveBrowserCredential.get_token failed: Failed to open a browser\nRegistered model &#39;databricks-diabetes-prediction&#39; already exists. Creating a new version of this model...\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\nInteractiveBrowserCredential.get_token failed: Failed to open a browser\n2022/11/28 09:37:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: databricks-diabetes-prediction, version 1\nCreated version &#39;1&#39; of model &#39;databricks-diabetes-prediction&#39;.\nOut[16]: &lt;ModelVersion: creation_timestamp=1669628232008, current_stage=&#39;None&#39;, description=&#39;&#39;, last_updated_timestamp=1669628232008, name=&#39;databricks-diabetes-prediction&#39;, run_id=&#39;&#39;, run_link=&#39;&#39;, source=&#39;azureml://artifacts/LocalUpload/221128T093710-01597558/model&#39;, status=&#39;READY&#39;, status_message=&#39;&#39;, tags={}, user_id=&#39;&#39;, version=&#39;1&#39;&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Summary:\n\nIn this tutorial we leaned how we can us mlflow for AML* ADB integration. We train and track a model in databricks & use Azure ML model registery to register the model .\nYou'll find your model in Azure ML workspace. You can check Job & model UI configuration for more details."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a82cacad-332f-4176-b2f4-303fc290f48f","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"databricks-train-model-MLflow-Tutorial-2-github (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2990136849975632,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":2240985617611280}},"nbformat":4,"nbformat_minor":0}
